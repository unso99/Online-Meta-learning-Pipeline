{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAML\n",
    "\n",
    "## Index\n",
    "1. Import Library  \n",
    "2. Path, Parameter, Hyper Parameter Setting  \n",
    "3. Custom Data Generator  \n",
    "4. Base Model\n",
    "5. MAML Meta Training\n",
    "6. Meta Test (Adaptation Performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5228,
     "status": "ok",
     "timestamp": 1685023291094,
     "user": {
      "displayName": "김동주",
      "userId": "11180573310054615837"
     },
     "user_tz": -540
    },
    "id": "CySIhrNAxQRZ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import layers, losses, metrics, optimizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Path, Parameter, Hyper Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1685023352236,
     "user": {
      "displayName": "김동주",
      "userId": "11180573310054615837"
     },
     "user_tz": -540
    },
    "id": "Qf5Qlre32RGU",
    "outputId": "a52ab476-b415-4882-d47e-1accdc90f6b4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "train_path: meta training support set에 사용될 dataset 경로\n",
    "test_path: meta training query set에 사용될 dataset 경로\n",
    "\n",
    "adaption_train_path: adaption performance를 확인하기 위한 train dataset 경로 (support, query로 분할)\n",
    "adaption_test_path: adaption performance를 확인하기 위한 test dataset 경로 (모델 성능 확인용 데이터셋)\n",
    "\n",
    "n_way_size: 목표 class 수\n",
    "k_shot_size: k_shot => class 당 사진 갯수. 여기서는 총 사진 갯수로 표현. n_way*k_shot\n",
    "\n",
    "learning_rate_outer: outer 모델(meta training 결과 모델)의 learning rate\n",
    "num_total_tasks: task의 수 (outer loop의 횟수)\n",
    "num_inner_updates: inner loop 속 base 모델의 업데이트 횟수\n",
    "learning_rate_inner: inner loop에서 base model의 learning rate\n",
    "\n",
    "'''\n",
    "\n",
    "train_path = '../dataset/cifar100/train_data/'\n",
    "test_path = '../dataset/cifar100/test_data/'\n",
    "adaption_train_path = '../dataset/cifar100/train_data/'\n",
    "adaption_test_path = '../dataset/cifar100/test_data/'\n",
    "\n",
    "n_way_size = 5\n",
    "k_shot_size = n_way_size * 3\n",
    "\n",
    "# MAML Training HyperParameter Setting\n",
    "learning_rate_outer = 0.001\n",
    "num_total_tasks = 150\n",
    "num_inner_updates = 15\n",
    "learning_rate_inner = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Custom Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task를 추출해야하며, 각 태스크 선정 후 이미지를 추출해야하기에 ImagedataGenerator를 활용하여 Custom datagenerator를 만들었습니다.  \n",
    "1. select_random_supper_class => CIFAR100의 상위 클래스(supper class)를 task로 랜덤하게 뽑습니다.  \n",
    "2. custom_generator => Meta training에 사용할 support set과 query set을 뽑는 과정입니다. 선정된 task의 하위 클래스에 관하여 batch_size 만큼 추출합니다. support set은 n way * k shot 만큼, query set은 n way 만큼의 데이터를 추출합니다.  \n",
    "3. adaption_test_generator => adaption performance 측정을 위한 adaption training 과정 data generator입니다. CIFAR10으로부터 5개의 클래스를 분리하여 training, testing과정에 사용합니다. custom_generator와 동일하게 support set과 query set을 뽑습니다.(1:0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n",
      "Found 8750 images belonging to 5 classes.\n",
      "Found 3750 images belonging to 5 classes.\n",
      "\n",
      "check shape of data shape\n",
      "input data shape from train_generator: (15, 256, 256, 3)\n",
      "class data shape from train_generator: (15, 5)\n",
      "\n",
      "input data shape from test_generator: (5, 256, 256, 3)\n",
      "class data shape from test_generator: (5, 5)\n",
      "\n",
      "input data shape from test_generator: (15, 256, 256, 3)\n",
      "class data shape from test_generator: (15, 5)\n",
      "\n",
      "input data shape from test_generator: (5, 256, 256, 3)\n",
      "class data shape from test_generator: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "class CustomGenerator():\n",
    "    def __init__(self, train_path: str, test_path: str, n_way_size: int, k_shot_size: int, adaption_train_path: str):\n",
    "        self.train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        self.test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        self.train_path = train_path\n",
    "        self.test_path = test_path\n",
    "        \n",
    "        self.original_class_list = sorted(os.listdir(train_path))\n",
    "        \n",
    "        self.n_way_size = n_way_size\n",
    "        self.k_shot_size = k_shot_size\n",
    "        \n",
    "        self.adaption_train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
    "        \n",
    "        self.adaption_train_path = adaption_train_path\n",
    "        \n",
    "    def select_random_supper_class(self):\n",
    "        super_class_select = (random.sample(self.original_class_list, 1))[0]\n",
    "        return super_class_select\n",
    "    \n",
    "    def custom_generator(self):\n",
    "        \n",
    "        random_supper_class = self.select_random_supper_class()\n",
    "        print(random_supper_class)\n",
    "        \n",
    "        supportset_generator = self.train_datagen.flow_from_directory(self.train_path+random_supper_class,\n",
    "                                                            batch_size = self.k_shot_size,\n",
    "                                                            target_size = (256, 256),\n",
    "                                                            subset=\"training\",\n",
    "                                                            class_mode='categorical', \n",
    "                                                            shuffle=True)\n",
    "\n",
    "\n",
    "        queryset_generator = self.test_datagen.flow_from_directory(self.test_path+random_supper_class,\n",
    "                                                          batch_size = self.n_way_size,\n",
    "                                                          target_size = (256, 256),\n",
    "                                                          class_mode='categorical', \n",
    "                                                          shuffle=True)\n",
    "        \n",
    "        # print(f\"selected random classes: {random_n_way}\")\n",
    "        \n",
    "        return supportset_generator, queryset_generator\n",
    "    \n",
    "    def adaption_test_generator(self):\n",
    "        \n",
    "        random_n_class = random.sample(os.listdir(self.adaption_train_path), 5)\n",
    "        \n",
    "        supportset_generator = self.adaption_train_datagen.flow_from_directory(self.adaption_train_path,\n",
    "                                                            classes=random_n_class,\n",
    "                                                            batch_size = self.k_shot_size,\n",
    "                                                            target_size = (256, 256),\n",
    "                                                            subset=\"training\",\n",
    "                                                            class_mode='categorical', \n",
    "                                                            shuffle=True)\n",
    "        \n",
    "        queryset_generator = self.adaption_train_datagen.flow_from_directory(self.adaption_train_path,\n",
    "                                                            classes=random_n_class,\n",
    "                                                            batch_size = self.n_way_size,\n",
    "                                                            target_size = (256, 256),\n",
    "                                                            subset=\"validation\",\n",
    "                                                            class_mode='categorical', \n",
    "                                                            shuffle=True)\n",
    "        return supportset_generator, queryset_generator\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# =============================class method test=================================\n",
    "test = CustomGenerator(train_path=train_path, test_path=test_path, n_way_size=n_way_size, k_shot_size=k_shot_size, adaption_train_path=adaption_train_path)\n",
    "supportset_generator, queryset_generator = test.custom_generator()\n",
    "adaption_supportset_generator, adaption_queryset_generator = test.adaption_test_generator()\n",
    "print()\n",
    "\n",
    "print(\"check shape of data shape\")\n",
    "for x_data, class_data in supportset_generator:\n",
    "    print(f\"input data shape from train_generator: {x_data.shape}\")\n",
    "    print(f\"class data shape from train_generator: {class_data.shape}\")\n",
    "    break\n",
    "\n",
    "print()\n",
    "for x_data, class_data in queryset_generator:\n",
    "    print(f\"input data shape from test_generator: {x_data.shape}\")\n",
    "    print(f\"class data shape from test_generator: {class_data.shape}\")\n",
    "    break    \n",
    "\n",
    "print()\n",
    "for x_data, class_data in adaption_supportset_generator:\n",
    "    print(f\"input data shape from test_generator: {x_data.shape}\")\n",
    "    print(f\"class data shape from test_generator: {class_data.shape}\")\n",
    "    break    \n",
    "\n",
    "print()\n",
    "for x_data, class_data in adaption_queryset_generator:\n",
    "    print(f\"input data shape from test_generator: {x_data.shape}\")\n",
    "    print(f\"class data shape from test_generator: {class_data.shape}\")\n",
    "    break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Base Model\n",
    "AlexNet, LeNet을 변형한 구조를 차용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet():\n",
    "    def __init__(self):\n",
    "        self.model = self.model_architecture()\n",
    "        \n",
    "    def model_architecture(self):\n",
    "        \n",
    "        model = keras.Sequential([\n",
    "            layers.Conv2D(96, (11, 11), strides=(4, 4), padding='valid', activation='relu', input_shape=(256, 256, 3)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "            layers.Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "            layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "            layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "            layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n",
    "            layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            # layers.Dense(10, activation='softmax')\n",
    "            layers.Dense(5, activation='softmax')  # 클래스 개수에 맞게 변경\n",
    "        ])\n",
    "        \n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet():\n",
    "    def __init__(self):\n",
    "        self.model = self.model_architecture()\n",
    "        \n",
    "    def model_architecture(self):\n",
    "        \n",
    "        model = keras.Sequential([\n",
    "            layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(256, 256, 3)),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            \n",
    "            layers.Conv2D(16, (5, 5), activation='relu'),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(120, activation='relu'),\n",
    "            layers.Dense(84, activation='relu'),\n",
    "            # layers.Dense(10, activation='softmax')\n",
    "            layers.Dense(5, activation='softmax')  # 클래스 개수에 맞게 변경\n",
    "        ])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. MAML Meta Training\n",
    "\n",
    "base_model_load => base model 아키텍쳐 로드  \n",
    "  \n",
    "maml_training\n",
    "- Outter : 총 정해둔 task만큼 loop 진행(base model Inner update) 및 최종 outer(meta trained) model 최적화\n",
    "- Inner : 각 task마다 base model training. task 시작에는 항상 업데이트한 outer model의 가중치를 들고 옴.\n",
    "- adaption_testing_for_training: adaption performance를 측정하기 위해서 test 데이터 셋의 support, query로 학습. meta test 단계에서 해당 모델의 performance를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML():\n",
    "    def __init__(self, n_way_size, k_shot_size, learning_rate_outer, num_total_tasks, num_inner_updates, learning_rate_inner):\n",
    "        self.n_way_size = n_way_size\n",
    "        self.k_shot_size = k_shot_size\n",
    "        self.learning_rate_outer = learning_rate_outer\n",
    "        self.num_total_tasks = num_total_tasks\n",
    "        self.num_inner_updates = num_inner_updates\n",
    "        self.learning_rate_inner = learning_rate_inner\n",
    "        \n",
    "        \n",
    "        self.loss_meta_training = []\n",
    "        self.loss_adaption_training = []\n",
    "        \n",
    "    \n",
    "    def base_model_load(self):\n",
    "        # Base 모델 구성\n",
    "        # 다른 파일에서 불러오는 것으로 변경하기\n",
    "        model = AlexNet()\n",
    "        model = model.model\n",
    "        return model\n",
    "    \n",
    "#     def base_model_compile(self, inner_or_outer):\n",
    "#         model_clone = keras.models.clone_model(self.base_model_load())\n",
    "#         model_clone.compile(loss='categorical_crossentropy', \n",
    "#                            optimizer = Adam(lr=inner_or_outer),\n",
    "#                            metrics=['accuracy'])\n",
    "        \n",
    "#         return model_clone\n",
    "    \n",
    "    \n",
    "    def maml_training(self):\n",
    "        \n",
    "        # Initialize the maml model's parameters.\n",
    "        ## maml optimizer 및 loss function check\n",
    "        \n",
    "        # maml_model = self.base_model_compile(inner_or_outer=self.learning_rate_outer)\n",
    "        maml_model = keras.models.clone_model(self.base_model_load())\n",
    "        maml_model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=self.learning_rate_outer), metrics=['accuracy'])\n",
    "        \n",
    "        # Repeat for a specified number of outer loop updates\n",
    "        # outer optimization: 여러 tasks에서 meta learner가 학습하는 과정\n",
    "            \n",
    "\n",
    "        # Allocate task\n",
    "        for task in range(self.num_total_tasks):\n",
    "            print(task)\n",
    "            # base model clone for each task inner learning\n",
    "            inner_clone_model = keras.models.clone_model(self.base_model_load())\n",
    "            inner_clone_model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=self.learning_rate_inner), metrics=['accuracy'])\n",
    "            # inner_clone_model.set_weights(maml_model.get_weights())\n",
    "            \n",
    "            # Load support set data, query set data generator for specified task\n",
    "            data_generator = CustomGenerator(train_path=train_path, test_path=test_path, n_way_size=self.n_way_size, k_shot_size=self.k_shot_size, adaption_train_path=adaption_train_path)\n",
    "            supportset_generator, queryset_generator = data_generator.custom_generator()\n",
    "\n",
    "            support_set_data, support_set_labels = supportset_generator.next()\n",
    "            query_set_data, query_set_labels = queryset_generator.next()\n",
    "            \n",
    "            \n",
    "            for inner_step in tqdm_notebook(range(num_inner_updates)):\n",
    "                with tf.GradientTape() as tape:\n",
    "\n",
    "                    predictions = inner_clone_model(support_set_data, training=True)\n",
    "                    #loss = tf.reduce_mean(tf.square(predictions-support_set_labels))\n",
    "                    #predictions = tf.one_hot(tf.argmax(predictions, axis=1), depth=predictions.shape[1])\n",
    "                    # loss = tf.reduce_mean(keras.losses.CategoricalCrossentropy(support_set_labels, predictions))\n",
    "                    loss_function = keras.losses.CategoricalCrossentropy()\n",
    "                    loss = loss_function(support_set_labels, predictions)\n",
    "\n",
    "                    gradients = tape.gradient(loss, inner_clone_model.trainable_variables)\n",
    "                    inner_clone_model.optimizer.apply_gradients(zip(gradients, inner_clone_model.trainable_variables))\n",
    "\n",
    "\n",
    "\n",
    "            # Compute the adaptation loss on an query set for the current task\n",
    "            with tf.GradientTape() as tape:\n",
    "                support_set_data, support_set_labels = supportset_generator.next()\n",
    "                query_set_data, query_set_labels = queryset_generator.next()\n",
    "                \n",
    "                # print(inner_clone_model(query_set_data, training=False))\n",
    "                adaption_loss = tf.reduce_mean(keras.losses.categorical_crossentropy(query_set_labels, inner_clone_model(query_set_data, training=False)))\n",
    "            \n",
    "            print(adaption_loss)\n",
    "            self.loss_meta_training.append(adaption_loss.numpy())\n",
    "            # Update the model parameters in the outer loop based on adaptation loss\n",
    "            \n",
    "            outer_gradients = tape.gradient(adaption_loss, maml_model.trainable_variables)\n",
    "            filtered_gradients = [grad for grad in outer_gradients if grad is not None]\n",
    "            maml_model.optimizer.apply_gradients(zip([-self.learning_rate_outer * grad for grad in filtered_gradients], maml_model.trainable_variables))\n",
    "\n",
    "        \n",
    "        self.meta_trained_model = maml_model\n",
    "        return maml_model\n",
    "    \n",
    "    \n",
    "    def adaption_testing_for_training(self):\n",
    "        \n",
    "        loaded_model = keras.models.clone_model(self.base_model_load())\n",
    "        loaded_model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=self.learning_rate_outer), metrics=['accuracy'])\n",
    "        loaded_model.set_weights(self.meta_trained_model.get_weights())\n",
    "\n",
    "        # Allocate task\n",
    "\n",
    "        # base model clone for each task inner learning\n",
    "        inner_clone_model = keras.models.clone_model(self.base_model_load())\n",
    "        inner_clone_model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=self.learning_rate_inner), metrics=['accuracy'])\n",
    "        inner_clone_model.set_weights(loaded_model.get_weights())\n",
    "\n",
    "        # Load support set data, query set data generator for specified task\n",
    "        data_generator = CustomGenerator(train_path=train_path, test_path=test_path, n_way_size=self.n_way_size, k_shot_size=self.k_shot_size, adaption_train_path=adaption_train_path)\n",
    "        supportset_generator, queryset_generator = data_generator.adaption_test_generator()\n",
    "\n",
    "        support_set_data, support_set_labels = supportset_generator.next()\n",
    "        query_set_data, query_set_labels = queryset_generator.next()\n",
    "\n",
    "\n",
    "\n",
    "        for inner_step in tqdm_notebook(range(num_inner_updates)):\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                predictions = inner_clone_model(support_set_data, training=True)\n",
    "                loss_function = keras.losses.CategoricalCrossentropy()\n",
    "                loss = loss_function(support_set_labels, predictions)\n",
    "\n",
    "                gradients = tape.gradient(loss, inner_clone_model.trainable_variables)\n",
    "                inner_clone_model.optimizer.apply_gradients(zip(gradients, inner_clone_model.trainable_variables))\n",
    "\n",
    "\n",
    "\n",
    "        # Compute the adaptation loss on an query set for the current task\n",
    "        with tf.GradientTape() as tape:\n",
    "            support_set_data, support_set_labels = supportset_generator.next()\n",
    "            query_set_data, query_set_labels = queryset_generator.next()\n",
    "\n",
    "            adaption_loss = tf.reduce_mean(keras.losses.categorical_crossentropy(query_set_labels, inner_clone_model(query_set_data, training=False)))\n",
    "\n",
    "        print(adaption_loss)\n",
    "        self.loss_meta_training.append(adaption_loss.numpy())\n",
    "        # Update the model parameters in the outer loop based on adaptation loss\n",
    "\n",
    "        outer_gradients = tape.gradient(adaption_loss, loaded_model.trainable_variables)\n",
    "        filtered_gradients = [grad for grad in outer_gradients if grad is not None]\n",
    "        loaded_model.optimizer.apply_gradients(zip([-self.learning_rate_outer * grad for grad in filtered_gradients], loaded_model.trainable_variables))\n",
    "\n",
    "        \n",
    "        self.loaded_model = loaded_model              \n",
    "        return loaded_model\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maml = MAML(n_way_size, k_shot_size, learning_rate_outer, num_total_tasks, num_inner_updates, learning_rate_inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-4826a1e65509>:60: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for inner_step in tqdm_notebook(range(num_inner_updates)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc5a0fe30fb4158b5dbbb50b1e85396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22.184925, shape=(), dtype=float32)\n",
      "1\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7ea57f27844cf899098a6dceb52503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.247752, shape=(), dtype=float32)\n",
      "2\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32a22ba70da448b874280c4ea89e80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(81.21157, shape=(), dtype=float32)\n",
      "3\n",
      "trees\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409f593d887548a3875bf9383a5e3832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(28.047613, shape=(), dtype=float32)\n",
      "4\n",
      "trees\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e817ae40bb745b0bd710a835b8acc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(17.790556, shape=(), dtype=float32)\n",
      "5\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac59afeeae6489f815dafc93eef247f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(20.892942, shape=(), dtype=float32)\n",
      "6\n",
      "food_containers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2f14fd2da041ba85df3189e2918e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(50.277824, shape=(), dtype=float32)\n",
      "7\n",
      "trees\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53e108d058848ecb55906fe048eaaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.958737, shape=(), dtype=float32)\n",
      "8\n",
      "food_containers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f22d7d12fc14d798dd69fcdcac650aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.1153474, shape=(), dtype=float32)\n",
      "9\n",
      "large_omnivores_and_herbivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed27a1c8e6c14cb08d69a8f6d3117348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(15.686884, shape=(), dtype=float32)\n",
      "10\n",
      "insects\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594e4a78d2b1402388a641b2fdfd7fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(37.330482, shape=(), dtype=float32)\n",
      "11\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb49293950d24016abbdf14be16bc2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(20.821928, shape=(), dtype=float32)\n",
      "12\n",
      "non-insect_invertebrates\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8f186787a24a83a76c9fa449d74e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.511349, shape=(), dtype=float32)\n",
      "13\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25eb7e48fb94439b9f84717282f596d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(39.7622, shape=(), dtype=float32)\n",
      "14\n",
      "large_man-made_outdoor_things\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc247c8d5df434e912edef3ff1358fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(67.66188, shape=(), dtype=float32)\n",
      "15\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff4d056068c464ba28b0746f597003a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.4001931, shape=(), dtype=float32)\n",
      "16\n",
      "non-insect_invertebrates\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f38bc4c61db41778dc5d4fc058868ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(52.447826, shape=(), dtype=float32)\n",
      "17\n",
      "household_furniture\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22de924646584aa3911bcb9ccb42b1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.073828, shape=(), dtype=float32)\n",
      "18\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f259826d264e4a6393edbc8f743df831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.384506, shape=(), dtype=float32)\n",
      "19\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9019394e86314e03a349f8ce801ffb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.150581, shape=(), dtype=float32)\n",
      "20\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8b00d367fb42a797409f2c66df3152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22.447615, shape=(), dtype=float32)\n",
      "21\n",
      "household_furniture\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710286887a84442e9f740fac6ef4ce50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(88.96054, shape=(), dtype=float32)\n",
      "22\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0ae53f54ff4567879168ed967f23f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18.51286, shape=(), dtype=float32)\n",
      "23\n",
      "large_omnivores_and_herbivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0df82a8a584420ad06ee70ec6521e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(17.810953, shape=(), dtype=float32)\n",
      "24\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291c7f4b14dd4f6cb280922c4d3b3f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(29.137873, shape=(), dtype=float32)\n",
      "25\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c548f15036840f9bd8d362227730c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.808575, shape=(), dtype=float32)\n",
      "26\n",
      "fruit_and_vegetables\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dbe9bb1d77446685a56309afaf4a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.3363547, shape=(), dtype=float32)\n",
      "27\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ff86177fca4a018afc25f3c1beed75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(52.87204, shape=(), dtype=float32)\n",
      "28\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e43425497b6430485621eb44236875c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.642813, shape=(), dtype=float32)\n",
      "29\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113487514a844d7a95e9ee1c220f9596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42.398552, shape=(), dtype=float32)\n",
      "30\n",
      "trees\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e579343224451792df33c82ea8ce6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.747645, shape=(), dtype=float32)\n",
      "31\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f585077aa05e48548c189e5902026381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.8022966, shape=(), dtype=float32)\n",
      "32\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac22318ef25431bb4caaae4d5c02426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(29.892487, shape=(), dtype=float32)\n",
      "33\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592d43d93c6d44dda025c5a0e4318686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(28.493954, shape=(), dtype=float32)\n",
      "34\n",
      "food_containers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d426d633d0844008b5343c350de89077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.485412, shape=(), dtype=float32)\n",
      "35\n",
      "insects\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2593d56afdb443796eadf38b5a62094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(19.639765, shape=(), dtype=float32)\n",
      "36\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ab1f883dc1d4b33aae57951307de8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(26.67869, shape=(), dtype=float32)\n",
      "37\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7104e9e12cb44eb1b636ac3a8b01d46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(33.403698, shape=(), dtype=float32)\n",
      "38\n",
      "household_furniture\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e5d8a149db415cbf8ea172f6c7eb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(52.172382, shape=(), dtype=float32)\n",
      "39\n",
      "aquatic_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18d8503c68d47f184924224e6be28d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(77.31591, shape=(), dtype=float32)\n",
      "40\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cc614c22874711b573d4fef41d0a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(76.74205, shape=(), dtype=float32)\n",
      "41\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62ce982b0d34869bc4ee92ce7f40e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(46.46112, shape=(), dtype=float32)\n",
      "42\n",
      "trees\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d9567a947241b7916e9933a97b3f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18.274961, shape=(), dtype=float32)\n",
      "43\n",
      "fruit_and_vegetables\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea921ef1df5483e8321251e59ddc178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.105193, shape=(), dtype=float32)\n",
      "44\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45211aa72bb49edba52d3ca5ad60b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.3052564, shape=(), dtype=float32)\n",
      "45\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeacbe41d8ea4913927138ab3cdf684e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(34.818882, shape=(), dtype=float32)\n",
      "46\n",
      "vehicles_2\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af409c326ad84d98861acae3df3e3789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22.851135, shape=(), dtype=float32)\n",
      "47\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1c2a6277874388b7fde8fff87890f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(38.53809, shape=(), dtype=float32)\n",
      "48\n",
      "large_omnivores_and_herbivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579b7d78b8fc436eb812a8291b920e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(25.947119, shape=(), dtype=float32)\n",
      "49\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d52047936f34761be78ae444e5afd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(23.01878, shape=(), dtype=float32)\n",
      "50\n",
      "aquatic_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69ec0a4a31c4bc1a37e84e0b02ee45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(37.793022, shape=(), dtype=float32)\n",
      "51\n",
      "food_containers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44c0f04be134f29930a74088c31bb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.453822, shape=(), dtype=float32)\n",
      "52\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbf38ca12a1427d8030e3c79179a363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(68.67595, shape=(), dtype=float32)\n",
      "53\n",
      "vehicles_2\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf1e461f69e4906a65d670b8301a091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.459157, shape=(), dtype=float32)\n",
      "54\n",
      "household_furniture\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c229c6a6a29f45bcac2137cb2b7a1140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(29.346249, shape=(), dtype=float32)\n",
      "55\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633eda9f94b64b1995c407dab6389cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(34.244385, shape=(), dtype=float32)\n",
      "56\n",
      "household_electrical_devices\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a921e7adc18428bb9a24bd21d32f199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.111372, shape=(), dtype=float32)\n",
      "57\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e1b62b76914a549ee0777723467a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(36.895634, shape=(), dtype=float32)\n",
      "58\n",
      "vehicles_2\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97db6f902f8942eba5581fcaf04214d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(16.730095, shape=(), dtype=float32)\n",
      "59\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06a4023c8c34872856515a3aeffa1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21.90483, shape=(), dtype=float32)\n",
      "60\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aeae800f0e479ab116c520e7f93947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18.517656, shape=(), dtype=float32)\n",
      "61\n",
      "large_omnivores_and_herbivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056ebfc3384e4f7a89ea79cf07bfc8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(15.610069, shape=(), dtype=float32)\n",
      "62\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a71f254424a46c4a7a4ca17d71ccd01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(24.258648, shape=(), dtype=float32)\n",
      "63\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2716240cd15e443ea147bef3d546c2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22.863636, shape=(), dtype=float32)\n",
      "64\n",
      "aquatic_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186b883ebf57479481f709b04bbbfef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(19.783726, shape=(), dtype=float32)\n",
      "65\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3981fe692694c03b8e3c6bea07a6f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(34.706486, shape=(), dtype=float32)\n",
      "66\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe624204aad94902832a0255375c8152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(48.280853, shape=(), dtype=float32)\n",
      "67\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5325be6f3c24fbab0a561caa6b6a4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(32.383045, shape=(), dtype=float32)\n",
      "68\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcc56be04da42558223e8d573e4b604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(32.483025, shape=(), dtype=float32)\n",
      "69\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ce982dcaf74c868c65b22a9698f8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18.999567, shape=(), dtype=float32)\n",
      "70\n",
      "aquatic_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a854271a5843c5a2f5bf1b735b8ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(29.268925, shape=(), dtype=float32)\n",
      "71\n",
      "large_man-made_outdoor_things\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc30bb0c1d91443193c8514e29722c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(26.985157, shape=(), dtype=float32)\n",
      "72\n",
      "household_electrical_devices\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e2c93af98745b997994d78857b2078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(29.457754, shape=(), dtype=float32)\n",
      "73\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a54c17fb328468a860e39121630d004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(23.23013, shape=(), dtype=float32)\n",
      "74\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36c040876a84d9f930cbec0565a628f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(34.026726, shape=(), dtype=float32)\n",
      "75\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b632241aad814356b6bb398328bd390d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(20.834026, shape=(), dtype=float32)\n",
      "76\n",
      "vehicles_2\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa1da764979c47ca882ee862458b4430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.3406563, shape=(), dtype=float32)\n",
      "77\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d20ab8eba64853a324c7ff6d0b5a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.6397157, shape=(), dtype=float32)\n",
      "78\n",
      "food_containers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a3e4353c6743eb9b906b078031239b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(36.544212, shape=(), dtype=float32)\n",
      "79\n",
      "aquatic_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f28b9219f1447f9df29aa76e34ed40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.289601, shape=(), dtype=float32)\n",
      "80\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4209807b5f4d4f37abbd2676ff8ac0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.98289, shape=(), dtype=float32)\n",
      "81\n",
      "large_omnivores_and_herbivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515228b72e404e72ba4f34bbda78d77b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.567169, shape=(), dtype=float32)\n",
      "82\n",
      "food_containers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145a5066d1cf4dc3a82b2fb647d79810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(30.684132, shape=(), dtype=float32)\n",
      "83\n",
      "insects\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1af38112474c8282ceadd1668d8f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(15.347397, shape=(), dtype=float32)\n",
      "84\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e3863bd7f34a3f8d96f4158491a616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18.147888, shape=(), dtype=float32)\n",
      "85\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c47364a2d2c423c9d2dcd7bac519bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(30.51067, shape=(), dtype=float32)\n",
      "86\n",
      "vehicles_1\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a304e51ba142d2ba4bb64b5cf9b929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(43.76995, shape=(), dtype=float32)\n",
      "87\n",
      "household_electrical_devices\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d80645cee4e4f9eada4755a9a8bd50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(32.048866, shape=(), dtype=float32)\n",
      "88\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a714a219ad164a59b331bca39db5bf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(24.181202, shape=(), dtype=float32)\n",
      "89\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac90498468c54dc6bab3e333109f1733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.991494, shape=(), dtype=float32)\n",
      "90\n",
      "large_man-made_outdoor_things\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1b23e4fda045d681bcac0f5649310b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(20.978863, shape=(), dtype=float32)\n",
      "91\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd9f3285f6541a686caef3f68be26ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.893576, shape=(), dtype=float32)\n",
      "92\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957bf45f62384f97a0cec325af4bf08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.8071046, shape=(), dtype=float32)\n",
      "93\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f3edf3b4ea4e5e8baf71af470e877e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(46.182175, shape=(), dtype=float32)\n",
      "94\n",
      "fruit_and_vegetables\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6967e263f5c4155b805e73fc35e9f0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(35.562668, shape=(), dtype=float32)\n",
      "95\n",
      "vehicles_1\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601424cfe0e5412b93357c000986eea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.9415, shape=(), dtype=float32)\n",
      "96\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbe7c1f25bf422a9d25ef9ed9c84c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.9773912, shape=(), dtype=float32)\n",
      "97\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d523841fa145b083cf5bae45875191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.851722, shape=(), dtype=float32)\n",
      "98\n",
      "vehicles_2\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b605ece67e421d95a78169e8fdc0ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.041597, shape=(), dtype=float32)\n",
      "99\n",
      "aquatic_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed63c398634d4dfea5ab9a4817d2a539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(30.41747, shape=(), dtype=float32)\n",
      "100\n",
      "household_electrical_devices\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983f331ab9ea407ebf6b43ca2ee6345c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.755359, shape=(), dtype=float32)\n",
      "101\n",
      "household_furniture\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8264988989d246ee8e4efede117a266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(39.0212, shape=(), dtype=float32)\n",
      "102\n",
      "vehicles_2\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490605ffb6a24941aae02c49e98155b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(30.878216, shape=(), dtype=float32)\n",
      "103\n",
      "fruit_and_vegetables\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8a9425e3e744908445e4462b20d59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(16.186651, shape=(), dtype=float32)\n",
      "104\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77020ebc71f4622a37ca67b78e9fc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.08575, shape=(), dtype=float32)\n",
      "105\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb6d473ee8949a4b634f366e04e68f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.07966, shape=(), dtype=float32)\n",
      "106\n",
      "large_man-made_outdoor_things\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e64c50b0f154ec391879008322b743f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.513607, shape=(), dtype=float32)\n",
      "107\n",
      "trees\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1a82efba3b4af6a3a2db6019407b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(51.40676, shape=(), dtype=float32)\n",
      "108\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df76659279c460baa339fbf9c9e885c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(26.420084, shape=(), dtype=float32)\n",
      "109\n",
      "insects\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03010a8fbe9442adbaa5e217efbcdd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.899435, shape=(), dtype=float32)\n",
      "110\n",
      "non-insect_invertebrates\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95f3f9a466e4afbb97622aed1b5442e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.039633, shape=(), dtype=float32)\n",
      "111\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba93d45339045448d6d1e0182fc6ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(12.246149, shape=(), dtype=float32)\n",
      "112\n",
      "insects\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74146bb661164d15b5ecabb1d21e8f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.385789, shape=(), dtype=float32)\n",
      "113\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b2bde474fe40fc866a98472fd43750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(53.346245, shape=(), dtype=float32)\n",
      "114\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41857428cf0c4800aa89611655ce1538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(25.045465, shape=(), dtype=float32)\n",
      "115\n",
      "large_natural_outdoor_scenes\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a53a6fcb6147f1875b75fe30764ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21.901829, shape=(), dtype=float32)\n",
      "116\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad05e6c82454a64aa0035b775ff8e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.294316, shape=(), dtype=float32)\n",
      "117\n",
      "reptiles\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf5f0ccb9164ef08db4bb49efcb378d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.764801, shape=(), dtype=float32)\n",
      "118\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9f21d3a2e54691967c965a480566f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.701439, shape=(), dtype=float32)\n",
      "119\n",
      "fruit_and_vegetables\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe01cc44727346d4a85d25d58813863d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.399622, shape=(), dtype=float32)\n",
      "120\n",
      "household_furniture\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fe1a542220494e9a24eb5e0a52872b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18.645603, shape=(), dtype=float32)\n",
      "121\n",
      "large_man-made_outdoor_things\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b59ed70dc4445dba99655c8b7280e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(8.021962, shape=(), dtype=float32)\n",
      "122\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03857737b5684d9cb7881cbc18d576b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(55.424305, shape=(), dtype=float32)\n",
      "123\n",
      "large_omnivores_and_herbivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1393d34ce84b61949a964da5d04acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.3978195, shape=(), dtype=float32)\n",
      "124\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc1ac5b27a145c586827c5135ba8827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22.303345, shape=(), dtype=float32)\n",
      "125\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180bf28745734ff7b82d209d792fd040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.287297, shape=(), dtype=float32)\n",
      "126\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31df51f63a98429aa5e382076cd84d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.527002, shape=(), dtype=float32)\n",
      "127\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486ee122557d45d0896719d6f938ac0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.7291458, shape=(), dtype=float32)\n",
      "128\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378860547bdc45b284a8127f1b25e652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(49.802788, shape=(), dtype=float32)\n",
      "129\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7cc1dc5a4d44dc90d17201d9a5e026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(41.057365, shape=(), dtype=float32)\n",
      "130\n",
      "household_electrical_devices\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28085e8d6cec491a92ec8fda18709370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(74.17513, shape=(), dtype=float32)\n",
      "131\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a567c0c9607f4675a51b076db09a7ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22.020927, shape=(), dtype=float32)\n",
      "132\n",
      "vehicles_1\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f790e1f5cad9401d9970e8a773a1c299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(14.138641, shape=(), dtype=float32)\n",
      "133\n",
      "vehicles_1\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a2fd89c4b742e3b8320e2fbc2b1891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(55.764824, shape=(), dtype=float32)\n",
      "134\n",
      "vehicles_1\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d927555abebb46dcbe1045aa3b883a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(40.717216, shape=(), dtype=float32)\n",
      "135\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a8581d3b0e492a9dbc5bd17f13f050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(11.771794, shape=(), dtype=float32)\n",
      "136\n",
      "small_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262b06047dbc417c938c976c55909751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3.613582, shape=(), dtype=float32)\n",
      "137\n",
      "large_man-made_outdoor_things\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bafd059293774101be8498b8656321bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(42.710686, shape=(), dtype=float32)\n",
      "138\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d709c75d7247a1965accad3c633975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.26401, shape=(), dtype=float32)\n",
      "139\n",
      "large_carnivores\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bcf9e0fe594352a26495079516d6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(51.750916, shape=(), dtype=float32)\n",
      "140\n",
      "medium_mammals\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4442c3e82bbb47218653fc2f4889d86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.889882, shape=(), dtype=float32)\n",
      "141\n",
      "food_containers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28a12aceb9a4439a07b51644aaafdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.9973555, shape=(), dtype=float32)\n",
      "142\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54a3cbc93e641f1b06d039e70cf4109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(13.3941145, shape=(), dtype=float32)\n",
      "143\n",
      "fish\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b1ff10e48446f2ac5f7ee290523074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(30.932526, shape=(), dtype=float32)\n",
      "144\n",
      "insects\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4768bebaf64906ad71308f78f7efa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(14.97805, shape=(), dtype=float32)\n",
      "145\n",
      "vehicles_2\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d781eeb743d54fce8743f4fb32336ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(50.03786, shape=(), dtype=float32)\n",
      "146\n",
      "household_electrical_devices\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c687a222ba00482e95f9383f36fe0fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(53.875267, shape=(), dtype=float32)\n",
      "147\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3f22b90e5c458eb27929fe1a7992e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(26.406452, shape=(), dtype=float32)\n",
      "148\n",
      "household_electrical_devices\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aafb962804e4393a58649ec5a1e74f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(27.753315, shape=(), dtype=float32)\n",
      "149\n",
      "flowers\n",
      "Found 2500 images belonging to 5 classes.\n",
      "Found 500 images belonging to 5 classes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c7ede99ff2427294b79abfca2912b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(21.013903, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "meta_learned_model = maml.maml_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Meta Test (Adaptation Performance)\n",
    "미리 cifar100으로부터 뽑아놓은 5개의 하위클래스(1개의 상위클래스)에 대해 training 및 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "adaption_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "random_n_class = random.sample(os.listdir(adaption_train_path), 5)\n",
    "random_n_class\n",
    "\n",
    "# random_n_class = random.sample(os.listdir(adaption_test_path), 5)\n",
    "adaption_test_generator = adaption_test_datagen.flow_from_directory(adaption_test_path,\n",
    "                                                  classes=random_n_class,\n",
    "                                                  batch_size = n_way_size,\n",
    "                                                  target_size = (256, 256),\n",
    "                                                  class_mode='categorical', \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-b27edfe7a534>:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  scores = meta_learned_model.evaluate_generator(adaption_test_generator, steps=adaption_test_generator.n//adaption_test_generator.batch_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.20%\n"
     ]
    }
   ],
   "source": [
    "scores = meta_learned_model.evaluate_generator(adaption_test_generator, steps=adaption_test_generator.n//adaption_test_generator.batch_size)\n",
    "print(\"%.2f%%\" %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8750 images belonging to 5 classes.\n",
      "Found 3750 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-4826a1e65509>:118: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for inner_step in tqdm_notebook(range(num_inner_updates)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eed13142ca5456da7382c5e1b50971c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(23.717129, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "adaption_trained_model = maml.adaption_testing_for_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-d1d5081a0446>:3: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  scores = adaption_trained_model.evaluate_generator(adaption_test_generator, steps=adaption_test_generator.n//adaption_test_generator.batch_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 19.20%\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "print(\"-- Evaluate --\")\n",
    "scores = adaption_trained_model.evaluate_generator(adaption_test_generator, steps=adaption_test_generator.n//adaption_test_generator.batch_size)\n",
    "print(\"%s: %.2f%%\" %(adaption_trained_model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMuq7kPgs1Cr9QUc0p0z1wT",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
