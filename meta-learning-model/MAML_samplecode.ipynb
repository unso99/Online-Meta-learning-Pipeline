{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMayt/1UMsD+GHVw9ucmhX0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"Aa2jvK7eFfAf","executionInfo":{"status":"ok","timestamp":1684082140515,"user_tz":-540,"elapsed":5934,"user":{"displayName":"김동주","userId":"11180573310054615837"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np"]},{"cell_type":"code","source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# unzip\n","import zipfile, os, shutil\n","\n","dataset = '/content/gdrive/My Drive/Colab_Notebooks/DL/datasets/cifar10.zip'\n","dst_path = '/content/cifa10'\n","dst_file = os.path.join(dst_path, 'cifar10.zip')\n","\n","if not os.path.exists(dst_path):\n","  os.makedirs(dst_path)\n","\n","# copy zip file\n","shutil.copy(dataset, dst_file)\n","  \n","with zipfile.ZipFile(dst_file, 'r') as file:\n","  file.extractall(dst_path)\n","\n","train_dir = os.path.join(dst_path, 'cifar10/train')\n","\n","test_dir = os.path.join(dst_path, 'cifar10/test')\n","\n","print('total training  images:', len(os.listdir(train_dir)))\n","\n","print('total test images:', len(os.listdir(test_dir)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m6VX_cNZGLe6","executionInfo":{"status":"ok","timestamp":1684082205236,"user_tz":-540,"elapsed":39935,"user":{"displayName":"김동주","userId":"11180573310054615837"}},"outputId":"004c9bb0-8359-425e-ca6f-bbad38793ef0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","total training  images: 10\n","total test images: 10\n"]}]},{"cell_type":"code","source":["# path\n","train_path = \"/content/cifa10/cifar10/train/\"\n","test_path = \"/content/cifa10/cifar10/test/\"\n","\n","# library\n","import keras\n","import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","import os\n","import scipy\n","\n","\n","\n","# load Neural Network Model Library => condition 3 of assignment\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D\n","# Set generator with rescaler(1./255) -> condition 2 of assignment\n","train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# make a loading data flow from path. It generates data at each batch sizes -> condition 1 of assignment\n","batch_size_num = 100\n","train_generator = train_datagen.flow_from_directory(train_path,\n","                                                    classes=sorted(os.listdir(train_path)),\n","                                                    batch_size = batch_size_num,\n","                                                    target_size = (256, 256),\n","                                                    subset=\"training\",\n","                                                    class_mode='categorical')\n","\n","valid_generator = train_datagen.flow_from_directory(train_path, \n","                                                    classes=sorted(os.listdir(train_path)), \n","                                                    batch_size = batch_size_num, \n","                                                    target_size=(256, 256), \n","                                                    subset=\"validation\",\n","                                                    class_mode='categorical')\n","\n","\n","test_generator = test_datagen.flow_from_directory(test_path, \n","                                                  classes=sorted(os.listdir(test_path)),\n","                                                  batch_size = 100,\n","                                                  target_size = (256, 256),\n","                                                  class_mode='categorical')\n","\n","print()\n","# check shape of data shape\n","print(\"check shape of data shape\")\n","for x_data, class_data in train_generator:\n","    print(f\"input data shape from train_generator: {x_data.shape}\")\n","    print(f\"class data shape from train_generator: {class_data.shape}\")\n","    break\n","\n","for x_data, class_data in valid_generator:\n","    print(f\"input data shape from valid_generator: {x_data.shape}\")\n","    print(f\"class data shape from valid_generator: {class_data.shape}\")\n","    break\n","    \n","for x_data, class_data in test_generator:\n","    print(f\"input data shape from test_generator: {x_data.shape}\")\n","    print(f\"class data shape from test_generator: {class_data.shape}\")\n","    break    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvPpK85cHoM-","executionInfo":{"status":"ok","timestamp":1684082220654,"user_tz":-540,"elapsed":1672,"user":{"displayName":"김동주","userId":"11180573310054615837"}},"outputId":"a64fd47a-52ad-4df1-c73e-11e7a37b28e1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 45000 images belonging to 10 classes.\n","Found 5000 images belonging to 10 classes.\n","Found 10000 images belonging to 10 classes.\n","\n","check shape of data shape\n","input data shape from train_generator: (100, 256, 256, 3)\n","class data shape from train_generator: (100, 10)\n","input data shape from valid_generator: (100, 256, 256, 3)\n","class data shape from valid_generator: (100, 10)\n","input data shape from test_generator: (100, 256, 256, 3)\n","class data shape from test_generator: (100, 10)\n"]}]},{"cell_type":"code","source":["from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n","\n","def create_alexnet_model():\n","# 모델 구성: AlexNet 모델\n","  model = Sequential()\n","\n","  # Convolutional layers  \n","  model.add(Conv2D(96, (11, 11), strides=(4, 4), padding='valid', activation='relu', input_shape=(256, 256, 3)))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","\n","  model.add(Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","\n","  model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n","\n","  model.add(Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n","\n","  model.add(Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n","\n","  model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n","  model.add(Flatten())\n","\n","  # Fully-connected layers\n","  model.add(Dense(4096, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","  model.add(Dense(4096, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","  model.add(Dense(1000, activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","\n","  model.add(Dense(10, activation='softmax'))\n","\n","  return model\n"],"metadata":{"id":"Cj8LoHnoHwPf","executionInfo":{"status":"ok","timestamp":1684083303120,"user_tz":-540,"elapsed":3,"user":{"displayName":"김동주","userId":"11180573310054615837"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def get_adaptation_batch(instance_x, instance_y, batch_size = 32):\n","    indices = np.random.choice(len(instance_x), size=batch_size, replace=False)\n","    batch_x = instance_x[indices]\n","    batch_y = instance_y[indices]\n","    return batch_x, batch_y"],"metadata":{"id":"BWCWNWBcPChQ","executionInfo":{"status":"ok","timestamp":1684084192791,"user_tz":-540,"elapsed":1,"user":{"displayName":"김동주","userId":"11180573310054615837"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# MAML 훈련\n","num_epochs = 10  # 적절한 훈련 반복 횟수 설정\n","num_tasks = 5  # 훈련 데이터로부터 생성할 작업 수\n","\n","train_losses = []\n","train_accuracies = []\n","val_losses = []\n","val_accuracies = []\n","\n","for epoch in range(num_epochs):\n","    train_loss_epoch = 0.0\n","    train_acc_epoch = 0.0\n","\n","    for task in range(num_tasks):\n","        # 작업 데이터로부터 인스턴스 생성\n","        instance_x, instance_y = train_generator.next()  # 적절한 작업 데이터에서 인스턴스 생성 함수를 사용하여 인스턴스 데이터 생성\n","        \n","        # 새로운 모델 생성 및 초기 파라미터 설정\n","        model = create_alexnet_model()  # 적절한 AlexNet 모델 생성 함수를 사용하여 모델 생성\n","        model.set_weights(initial_weights)  # 초기 파라미터 설정 -> 사전 훈련된 모델의 가중치로 설정\n","        \n","        # 작업 적응 단계 진행 -> task임 num_adaptation_step이 5면은 task가 5개라는 소리임 \n","        for adaptation_step in range(num_adaptation_steps): # 보통 1~5의 값을 넣음 근데 초기에는 1~3정도를 넣어보고 실험을 해보면서 모델성능이 좋아지는봐야함 숫자 클수록 좋지만 그만큼 학습속도도 오래걸리고 오버피팅이 걸림\n","            # 작업 데이터에서 배치 생성\n","            batch_x, batch_y = get_adaptation_batch(instance_x, instance_y)  # 적절한 작업 데이터에서 배치 생성 함수를 사용하여 배치 생성\n","            \n","            # 모델 업데이트 (적응 단계에서 역전파 진행)\n","            model.train_on_batch(batch_x, batch_y)  # 모델의 파라미터 업데이트\n","\n","        # 훈련 데이터로 평가\n","        train_loss, train_acc = model.evaluate(instance_x, instance_y)\n","        train_loss_epoch += train_loss\n","        train_acc_epoch += train_acc\n","        \n","        # 검증 데이터로 평가\n","        val_loss, val_acc = model.evaluate(valid_generator)\n","        val_losses.append(val_loss)\n","        val_accuracies.append(val_acc)\n","\n","     # 평균 훈련 손실과 정확도 계산\n","    train_loss_epoch /= num_tasks\n","    train_acc_epoch /= num_tasks\n","    train_losses.append(train_loss_epoch)\n","    train_accuracies.append(train_acc_epoch)\n","\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    print(f\"Train Loss: {train_loss_epoch:.4f} - Train Accuracy: {train_acc_epoch:.4f}\")\n","    print(f\"Val Loss: {val_loss:.4f} - Val Accuracy: {val_acc:.4f}\")\n","    print()\n"],"metadata":{"id":"-CeUpcdgKPnQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 데이터로 평가\n","test_loss, test_acc = model.evaluate(test_generator)  \n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"id":"SXsmeKYZRzd9"},"execution_count":null,"outputs":[]}]}