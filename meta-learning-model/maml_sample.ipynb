{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMuq7kPgs1Cr9QUc0p0z1wT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"CySIhrNAxQRZ","executionInfo":{"status":"ok","timestamp":1685023291094,"user_tz":-540,"elapsed":5228,"user":{"displayName":"김동주","userId":"11180573310054615837"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np"]},{"cell_type":"code","source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# unzip\n","import zipfile, os, shutil\n","\n","dataset = '/content/gdrive/My Drive/Colab_Notebooks/DL/datasets/cifar10.zip'\n","dst_path = '/content/cifa10'\n","dst_file = os.path.join(dst_path, 'cifar10.zip')\n","\n","if not os.path.exists(dst_path):\n","  os.makedirs(dst_path)\n","\n","# copy zip file\n","shutil.copy(dataset, dst_file)\n","  \n","with zipfile.ZipFile(dst_file, 'r') as file:\n","  file.extractall(dst_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcgJEcYwxfQN","executionInfo":{"status":"ok","timestamp":1685023343499,"user_tz":-540,"elapsed":39769,"user":{"displayName":"김동주","userId":"11180573310054615837"}},"outputId":"e373d368-9c91-4fc1-ad33-f147ccad5f50"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["train_dir = os.path.join(dst_path, 'cifar10/train')\n","\n","test_dir = os.path.join(dst_path, 'cifar10/test')\n","\n","print('total training  images:', len(os.listdir(train_dir)))\n","\n","print('total test images:', len(os.listdir(test_dir)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qf5Qlre32RGU","executionInfo":{"status":"ok","timestamp":1685023352236,"user_tz":-540,"elapsed":396,"user":{"displayName":"김동주","userId":"11180573310054615837"}},"outputId":"a52ab476-b415-4882-d47e-1accdc90f6b4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["total training  images: 10\n","total test images: 10\n"]}]},{"cell_type":"code","source":["# path\n","train_path = \"/content/cifa10/cifar10/train/\"\n","test_path = \"/content/cifa10/cifar10/test/\""],"metadata":{"id":"MVKDgTFi2VCT","executionInfo":{"status":"ok","timestamp":1685023358284,"user_tz":-540,"elapsed":688,"user":{"displayName":"김동주","userId":"11180573310054615837"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# library\n","import keras\n","import numpy as np\n","from keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","import os\n","import scipy\n","\n","\n","\n","# load Neural Network Model Library => condition 3 of assignment\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n","from keras.layers import Conv2D, MaxPooling2D\n","# Set generator with rescaler(1./255) -> condition 2 of assignment\n","train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# make a loading data flow from path. It generates data at each batch sizes -> condition 1 of assignment\n","batch_size_num = 100\n","train_generator = train_datagen.flow_from_directory(train_path,\n","                                                    classes=sorted(os.listdir(train_path)),\n","                                                    batch_size = batch_size_num,\n","                                                    target_size = (256, 256),\n","                                                    subset=\"training\",\n","                                                    class_mode='categorical')\n","\n","valid_generator = train_datagen.flow_from_directory(train_path, \n","                                                    classes=sorted(os.listdir(train_path)), \n","                                                    batch_size = batch_size_num, \n","                                                    target_size=(256, 256), \n","                                                    subset=\"validation\",\n","                                                    class_mode='categorical')\n","\n","\n","test_generator = test_datagen.flow_from_directory(test_path, \n","                                                  classes=sorted(os.listdir(test_path)),\n","                                                  batch_size = 100,\n","                                                  target_size = (256, 256),\n","                                                  class_mode='categorical')\n","\n","print()\n","# check shape of data shape\n","print(\"check shape of data shape\")\n","for x_data, class_data in train_generator:\n","    print(f\"input data shape from train_generator: {x_data.shape}\")\n","    print(f\"class data shape from train_generator: {class_data.shape}\")\n","    break\n","\n","for x_data, class_data in valid_generator:\n","    print(f\"input data shape from valid_generator: {x_data.shape}\")\n","    print(f\"class data shape from valid_generator: {class_data.shape}\")\n","    break\n","    \n","for x_data, class_data in test_generator:\n","    print(f\"input data shape from test_generator: {x_data.shape}\")\n","    print(f\"class data shape from test_generator: {class_data.shape}\")\n","    break    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFYlECa62WmH","executionInfo":{"status":"ok","timestamp":1685023373319,"user_tz":-540,"elapsed":1746,"user":{"displayName":"김동주","userId":"11180573310054615837"}},"outputId":"cc4e1359-fa96-44fd-db15-7cd35cfc3a0a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 45000 images belonging to 10 classes.\n","Found 5000 images belonging to 10 classes.\n","Found 10000 images belonging to 10 classes.\n","\n","check shape of data shape\n","input data shape from train_generator: (100, 256, 256, 3)\n","class data shape from train_generator: (100, 10)\n","input data shape from valid_generator: (100, 256, 256, 3)\n","class data shape from valid_generator: (100, 10)\n","input data shape from test_generator: (100, 256, 256, 3)\n","class data shape from test_generator: (100, 10)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import numpy as np\n","\n","# MAML 모델 구성\n","model = keras.Sequential([\n","    layers.Conv2D(96, (11, 11), strides=(4, 4), padding='valid', activation='relu', input_shape=(256, 256, 3)),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n","    layers.Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n","    layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n","    layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n","    layers.Conv2D(256, (3, 3), strides=(1, 1), padding='same', activation='relu'),\n","    layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(512, activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.Dropout(0.5),\n","    layers.Dense(256, activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.Dropout(0.5),\n","    layers.Dense(128, activation='relu'),\n","    layers.BatchNormalization(),\n","    layers.Dropout(0.5),\n","    # layers.Dense(10, activation='softmax')\n","    layers.Dense(5, activation='softmax')  # 클래스 개수에 맞게 변경\n","])"],"metadata":{"id":"1lWBDRfFxSSB","executionInfo":{"status":"ok","timestamp":1685025438509,"user_tz":-540,"elapsed":340,"user":{"displayName":"김동주","userId":"11180573310054615837"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["# MAML 모델 컴파일\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"],"metadata":{"id":"rWqbRRqd2-qO","executionInfo":{"status":"ok","timestamp":1685025441238,"user_tz":-540,"elapsed":2,"user":{"displayName":"김동주","userId":"11180573310054615837"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["# MAML 알고리즘 설정\n","meta_learning_rate = 0.001\n","inner_learning_rate = 0.01\n","num_tasks = 450\n","num_inner_updates = 1"],"metadata":{"id":"tKsIt8uF3BMs","executionInfo":{"status":"ok","timestamp":1685025453004,"user_tz":-540,"elapsed":3,"user":{"displayName":"김동주","userId":"11180573310054615837"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["# 메타-학습 반복\n","for meta_iteration in range(num_tasks):\n","    # task_indices = np.random.choice(len(x_train), num_tasks, replace=False)\n","\n","    # 작업 별로 초기 파라미터 설정\n","    model_clone = keras.models.clone_model(model)\n","    model_clone.set_weights(model.get_weights())\n","    model_clone.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","    \n","    # train_generator의 클래스 개수\n","    num_classes = len(train_generator.class_indices)\n","\n","    for inner_iteration in range(num_inner_updates):\n","       # 랜덤하게 5개의 클래스 선택\n","      random_classes = np.random.choice(num_classes, size=5, replace=False)\n","    \n","      # 선택한 클래스에 해당하는 데이터로 작업 데이터 생성\n","      x_task_train = []\n","      y_task_train = []\n","    for cls in random_classes:\n","        # 해당 클래스에 속하는 이미지들을 가져옴\n","        images, labels = train_generator.next()\n","        # 클래스에 해당하는 이미지와 레이블을 작업 데이터에 추가\n","        x_task_train.append(images)\n","        y_task_train.append(labels)\n","\n","        # 작업 데이터를 numpy 배열로 변환\n","    x_task_train = np.concatenate(x_task_train, axis=0)\n","    y_task_train = np.concatenate(y_task_train, axis=0)\n","\n","    selected_classes = np.random.choice(10, size=5, replace=False)\n","\n","    # 선택된 클래스들에 해당하는 인덱스를 추출하여 새로운 x_task_train과 y_task_train 생성\n","    selected_indices = np.isin(y_task_train.argmax(axis=1), selected_classes)\n","\n","    x_task_train_selected = x_task_train[selected_indices]\n","    y_task_train_selected = y_task_train[selected_indices][:, selected_classes]\n","\n","    for inner_iteration in range(num_inner_updates):\n","        # x_task_train, y_task_train = train_generator.next()\n","\n","        # 그래디언트 계산을 위해 작업 데이터로 모델 학습\n","        model_clone.train_on_batch(x_task_train_selected, y_task_train_selected)\n","        \n","        # 미세 조정을 위해 학습한 모델 파라미터를 업데이트\n","        model_weights = model_clone.get_weights()\n","        model.set_weights(model_weights)\n","\n","    # 메타-학습을 위해 초기 파라미터를 업데이트\n","    model_weights = model.get_weights()\n","    for i, weight in enumerate(model_weights):\n","        model_weights[i] = weight + meta_learning_rate * (weight - model_clone.get_weights()[i])\n","    model.set_weights(model_weights)\n","\n","\n","    # 선택한 클래스에 해당하는 데이터로 작업 데이터 생성\n","    x_task_val = []\n","    y_task_val = []\n","    # 현재 meta_iteration에서의 val 데이터셋에 대한 손실과 정확도 출력\n","    for cls in random_classes:\n","        # 해당 클래스에 속하는 이미지들을 가져옴\n","        images1, labels1 = valid_generator.next()\n","        # 클래스에 해당하는 이미지와 레이블을 작업 데이터에 추가\n","        x_task_val.append(images)\n","        y_task_val.append(labels)\n","\n","        # 작업 데이터를 numpy 배열로 변환\n","    x_task_val = np.concatenate(x_task_val, axis=0)\n","    y_task_val = np.concatenate(y_task_val, axis=0)\n","\n","    x_task_val_selected = x_task_val[selected_indices]\n","    y_task_val_selected = y_task_val[selected_indices][:, selected_classes]\n","\n","    # x_val, y_val = valid_generator.next()\n","    val_loss, val_acc = model.evaluate(x_task_val_selected, y_task_val_selected)\n","    print(f\"Meta Iteration: {meta_iteration + 1}  val Loss: {val_loss:.4f} val Acc: {val_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"5pasH60E3DP4","executionInfo":{"status":"error","timestamp":1685026069182,"user_tz":-540,"elapsed":69396,"user":{"displayName":"김동주","userId":"11180573310054615837"}},"outputId":"b3e83f01-57c6-44eb-bfd5-78df86cdd0bb"},"execution_count":48,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-db22221d6488>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# x_val, y_val = valid_generator.next()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_task_val_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_task_val_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Meta Iteration: {meta_iteration + 1}  val Loss: {val_loss:.4f} val Acc: {val_acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    933\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         raise ValueError(\"Creating variables on a non-first call to a function\"\n\u001b[0m\u001b[1;32m    936\u001b[0m                          \" decorated with tf.function.\")\n\u001b[1;32m    937\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."]}]},{"cell_type":"code","source":["x_test, y_test = test_generator.next()"],"metadata":{"id":"t2-EloQBgy77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# MAML 모델 평가\n","test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n","print(\"Test Accuracy:\", test_acc)"],"metadata":{"id":"LYkxUUF13H4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.predict(x_test)"],"metadata":{"id":"Ob-2AevVgcDR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save(\"aaaa.h5\")"],"metadata":{"id":"YfhGGrTqBmnn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"24kWdRLlXDRk"},"execution_count":null,"outputs":[]}]}